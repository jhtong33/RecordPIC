{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "680e6fdc-aaef-4f37-bc1d-a4d6c3c9cc40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.0.251-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting text2vec\n",
      "  Downloading text2vec-1.2.2.tar.gz (72 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (5.4.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
      "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.11 (from langchain)\n",
      "  Downloading langsmith-0.0.18-py3-none-any.whl (31 kB)\n",
      "Collecting numexpr<3.0.0,>=2.8.4 (from langchain)\n",
      "  Downloading numexpr-2.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (381 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.4/381.4 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (1.24.3)\n",
      "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n",
      "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (1.10.7)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (2.29.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain) (8.2.2)\n",
      "Collecting jieba (from text2vec)\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting loguru (from text2vec)\n",
      "  Downloading loguru-0.7.0-py3-none-any.whl (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting transformers (from text2vec)\n",
      "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting datasets (from text2vec)\n",
      "  Downloading datasets-2.14.3-py3-none-any.whl (519 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.1/519.1 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from text2vec) (4.65.0)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from text2vec) (1.2.2)\n",
      "Collecting gensim>=4.0.0 (from text2vec)\n",
      "  Downloading gensim-4.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from text2vec) (1.5.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.7/225.7 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from gensim>=4.0.0->text2vec) (1.10.1)\n",
      "Collecting smart-open>=1.8.1 (from gensim>=4.0.0->text2vec)\n",
      "  Downloading smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (613 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m613.7/613.7 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->text2vec) (12.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->text2vec) (0.3.6)\n",
      "Collecting xxhash (from datasets->text2vec)\n",
      "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->text2vec) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->text2vec) (2023.5.0)\n",
      "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets->text2vec)\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->text2vec) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->text2vec) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->text2vec) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn->text2vec) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn->text2vec) (3.1.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers->text2vec) (3.12.0)\n",
      "Collecting regex!=2019.12.17 (from transformers->text2vec)\n",
      "  Downloading regex-2023.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.4/770.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers->text2vec)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers->text2vec)\n",
      "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging->datasets->text2vec) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->text2vec) (1.16.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Building wheels for collected packages: text2vec, jieba\n",
      "  Building wheel for text2vec (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for text2vec: filename=text2vec-1.2.2-py3-none-any.whl size=58394 sha256=d9225cb46b01cc0d2a5cfb638efbccc3e4639f9ea2a7534b6547552ab09650a9\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/c2/5a/11/b86f7e1d668a1db00867f195f1364d8dd7e5cf495f5d6811dc\n",
      "  Building wheel for jieba (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314458 sha256=4ab4389467ebd2d5aef3ef5ba60e9678ef80ef728bbabb803e1ab686ad734bfc\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/c9/69/31/d56d90b22a1777b0b231e234b00302a55be255930f8bd92dcd\n",
      "Successfully built text2vec jieba\n",
      "Installing collected packages: tokenizers, safetensors, jieba, xxhash, smart-open, regex, numexpr, mypy-extensions, multidict, loguru, greenlet, frozenlist, async-timeout, yarl, typing-inspect, SQLAlchemy, openapi-schema-pydantic, marshmallow, langsmith, huggingface-hub, gensim, aiosignal, transformers, dataclasses-json, aiohttp, langchain, datasets, text2vec\n",
      "Successfully installed SQLAlchemy-2.0.19 aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.2 dataclasses-json-0.5.14 datasets-2.14.3 frozenlist-1.4.0 gensim-4.3.1 greenlet-2.0.2 huggingface-hub-0.16.4 jieba-0.42.1 langchain-0.0.251 langsmith-0.0.18 loguru-0.7.0 marshmallow-3.20.1 multidict-6.0.4 mypy-extensions-1.0.0 numexpr-2.8.4 openapi-schema-pydantic-1.2.4 regex-2023.6.3 safetensors-0.3.1 smart-open-6.3.0 text2vec-1.2.2 tokenizers-0.13.3 transformers-4.31.0 typing-inspect-0.9.0 xxhash-3.3.0 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain text2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a00be456-0236-4a3d-a821-a7b837c4a3e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('workflow_asset/catogory_sample.json', 'r') as f:\n",
    "    category = json.loads(f.read())\n",
    "    \n",
    "with open('workflow_asset/catogory_sample_generate.json', 'r') as f:\n",
    "    category_generate = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72744127-d5a3-4776-b177-8ab63ae62724",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d8cdd74-2217-4777-b27d-3ba07b943a72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_sample():\n",
    "    \n",
    "    for c, v in category.items():\n",
    "        for product_sample in v:\n",
    "            yield c, product_sample\n",
    "\n",
    "        for product_sample in category_generate[c]:\n",
    "            yield c, product_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6070421c-f660-4a43-8f2b-2eac43d47313",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(generate_sample(), columns=['category', 'sample'])\n",
    "df['cs'] = df['category']+'-'+df['sample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54e929e9-b954-4db7-b548-34c89e72fbfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS, Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d395ca-f081-4148-a6be-2840684afd5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b944da73-8fcf-4215-9cff-51334e012374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from text2vec import SentenceModel\n",
    "model = SentenceModel('shibing624/text2vec-base-chinese')\n",
    "embeddings = model.encode(df['sample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3ecd3c-24dd-42e5-82a6-024a9fb5ec56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langchain.vectorstores.utils import DistanceStrategy\n",
    "# from langchain.schema import Document\n",
    "# docs = list(map(lambda x: Document(page_content=x[1]['cs'], metadata=x[1]), df.iterrows()))\n",
    "# vdb = FAISS.from_embeddings(docs, embeddings, normalize_L2=True, distance_strategy=DistanceStrategy.COSINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2f5f55-b0c3-4ed1-abb2-36df2e0677f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional\n",
    "from text2vec import SentenceModel\n",
    "\n",
    "class EmbeddingModel():\n",
    "    def __init__(self, model='shibing624/text2vec-base-chinese', **kwargs):\n",
    "\n",
    "        self.embedding_model = SentenceModel()\n",
    "\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Compute doc embeddings using a Bedrock model.\n",
    "\n",
    "        Args:\n",
    "            texts: The list of texts to embed.\n",
    "\n",
    "        Returns:\n",
    "            List of embeddings, one for each text.\n",
    "        \"\"\"\n",
    "        return self.embedding_model.encode(texts)\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"Compute query embeddings using a Bedrock model.\n",
    "\n",
    "        Args:\n",
    "            text: The text to embed.\n",
    "\n",
    "        Returns:\n",
    "            Embeddings for the text.\n",
    "        \"\"\"\n",
    "        return self.embedding_model.encode([text])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde28d5c-76d1-417e-845a-a59ee543976a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.vectorstores.utils import DistanceStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c41244-fa61-4df7-8a1c-e7588f8cca74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "match_col = 'sample' # cs, sample, category\n",
    "docs = list(map(lambda x: Document(page_content=x[1][match_col], metadata=x[1]), df.iterrows()))\n",
    "vdb = FAISS.from_documents(docs, EmbeddingModel(), normalize_L2=False, distance_strategy=DistanceStrategy.COSINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0de2aa-019a-46a7-b594-2e0ecbce3ad6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7da931e-ecfd-4186-a8f5-c768c8457148",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_samples = pd.read_csv('data/samples.csv', index_col=0)\n",
    "df_samples = df_samples[df_samples['item_name'].apply(lambda x: '外送費' not in x)]\n",
    "df_samples = df_samples[df_samples['item_name'].apply(lambda x: '平台費' not in x)]\n",
    "df_samples = df_samples[df_samples['category'].apply(lambda x: '其他' not in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8bb64e-34a3-455d-a945-745dcf32dd4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "item = df_samples.sample(1).iloc[0]\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa58e217-e325-48c9-88d0-01215a0db2a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "item_name = item['item_name']\n",
    "item_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a64d5ee-81a5-4bd8-a317-79711a1cd3de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vdb.similarity_search_with_score(item_name, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc58faf1-2668-49e3-9954-92c8dd070fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0506bfa2-27a0-438a-8e4a-407d499e828b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108ac459-a921-4a47-9162-e7cb11a81394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157fcfcb-f9af-43ca-b00a-92adf3d8aad5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ea0013-28b8-48a3-a6e6-b6ac8d4c8bce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "edc0e525-9149-42f5-a176-ab680c4870b2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-7:\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process ForkPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-4:\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/tmp/ipykernel_31150/4212614069.py\", line 3, in classify\n",
      "    return vdb.similarity_search(item_name, k=1)[0].metadata['category']\n",
      "  File \"/tmp/ipykernel_31150/4212614069.py\", line 3, in classify\n",
      "    return vdb.similarity_search(item_name, k=1)[0].metadata['category']\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain/vectorstores/faiss.py\", line 326, in similarity_search\n",
      "    docs_and_scores = self.similarity_search_with_score(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "Process ForkPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/tmp/ipykernel_31150/4212614069.py\", line 3, in classify\n",
      "    return vdb.similarity_search(item_name, k=1)[0].metadata['category']\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain/vectorstores/faiss.py\", line 326, in similarity_search\n",
      "    docs_and_scores = self.similarity_search_with_score(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain/vectorstores/faiss.py\", line 267, in similarity_search_with_score\n",
      "    embedding = self.embedding_function(query)\n",
      "  File \"/tmp/ipykernel_31150/779960508.py\", line 30, in embed_query\n",
      "    return self.embedding_model.encode([text])[0]\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/text2vec/sentence_model.py\", line 177, in encode\n",
      "    embeddings = self.get_sentence_embeddings(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/text2vec/sentence_model.py\", line 102, in get_sentence_embeddings\n",
      "    model_output = self.bert(input_ids, attention_mask, token_type_ids, output_hidden_states=True)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain/vectorstores/faiss.py\", line 267, in similarity_search_with_score\n",
      "    embedding = self.embedding_function(query)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 1022, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "  File \"/tmp/ipykernel_31150/779960508.py\", line 30, in embed_query\n",
      "    return self.embedding_model.encode([text])[0]\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/text2vec/sentence_model.py\", line 177, in encode\n",
      "    embeddings = self.get_sentence_embeddings(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 612, in forward\n",
      "    layer_outputs = layer_module(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/text2vec/sentence_model.py\", line 102, in get_sentence_embeddings\n",
      "    model_output = self.bert(input_ids, attention_mask, token_type_ids, output_hidden_states=True)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_31150/4212614069.py\", line 3, in classify\n",
      "    return vdb.similarity_search(item_name, k=1)[0].metadata['category']\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 1022, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain/vectorstores/faiss.py\", line 326, in similarity_search\n",
      "    docs_and_scores = self.similarity_search_with_score(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain/vectorstores/faiss.py\", line 326, in similarity_search\n",
      "    docs_and_scores = self.similarity_search_with_score(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain/vectorstores/faiss.py\", line 267, in similarity_search_with_score\n",
      "    embedding = self.embedding_function(query)\n",
      "  File \"/tmp/ipykernel_31150/779960508.py\", line 30, in embed_query\n",
      "    return self.embedding_model.encode([text])[0]\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/text2vec/sentence_model.py\", line 177, in encode\n",
      "    embeddings = self.get_sentence_embeddings(\n",
      "  File \"/tmp/ipykernel_31150/4212614069.py\", line 3, in classify\n",
      "    return vdb.similarity_search(item_name, k=1)[0].metadata['category']\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain/vectorstores/faiss.py\", line 326, in similarity_search\n",
      "    docs_and_scores = self.similarity_search_with_score(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain/vectorstores/faiss.py\", line 267, in similarity_search_with_score\n",
      "    embedding = self.embedding_function(query)\n",
      "  File \"/tmp/ipykernel_31150/779960508.py\", line 30, in embed_query\n",
      "    return self.embedding_model.encode([text])[0]\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/text2vec/sentence_model.py\", line 102, in get_sentence_embeddings\n",
      "    model_output = self.bert(input_ids, attention_mask, token_type_ids, output_hidden_states=True)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/text2vec/sentence_model.py\", line 177, in encode\n",
      "    embeddings = self.get_sentence_embeddings(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/text2vec/sentence_model.py\", line 102, in get_sentence_embeddings\n",
      "    model_output = self.bert(input_ids, attention_mask, token_type_ids, output_hidden_states=True)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 1022, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 612, in forward\n",
      "    layer_outputs = layer_module(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 1022, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 539, in forward\n",
      "    layer_output = apply_chunking_to_forward(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 612, in forward\n",
      "    layer_outputs = layer_module(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/pytorch_utils.py\", line 239, in apply_chunking_to_forward\n",
      "    return forward_fn(*input_tensors)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 497, in forward\n",
      "    self_attention_outputs = self.attention(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 551, in feed_forward_chunk\n",
      "    intermediate_output = self.intermediate(attention_output)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 427, in forward\n",
      "    self_outputs = self.self(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 451, in forward\n",
      "    hidden_states = self.dense(hidden_states)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 286, in forward\n",
      "    mixed_query_layer = self.query(hidden_states)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 539, in forward\n",
      "    layer_output = apply_chunking_to_forward(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain/vectorstores/faiss.py\", line 267, in similarity_search_with_score\n",
      "    embedding = self.embedding_function(query)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_31150/779960508.py\", line 30, in embed_query\n",
      "    return self.embedding_model.encode([text])[0]\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 612, in forward\n",
      "    layer_outputs = layer_module(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/pytorch_utils.py\", line 239, in apply_chunking_to_forward\n",
      "    return forward_fn(*input_tensors)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 551, in feed_forward_chunk\n",
      "    intermediate_output = self.intermediate(attention_output)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/text2vec/sentence_model.py\", line 177, in encode\n",
      "    embeddings = self.get_sentence_embeddings(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 451, in forward\n",
      "    hidden_states = self.dense(hidden_states)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/text2vec/sentence_model.py\", line 102, in get_sentence_embeddings\n",
      "    model_output = self.bert(input_ids, attention_mask, token_type_ids, output_hidden_states=True)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 1022, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 497, in forward\n",
      "    self_attention_outputs = self.attention(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 612, in forward\n",
      "    layer_outputs = layer_module(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 427, in forward\n",
      "    self_outputs = self.self(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 539, in forward\n",
      "    layer_output = apply_chunking_to_forward(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 286, in forward\n",
      "    mixed_query_layer = self.query(hidden_states)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/tmp/ipykernel_31150/4212614069.py\", line 3, in classify\n",
      "    return vdb.similarity_search(item_name, k=1)[0].metadata['category']\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/tmp/ipykernel_31150/779960508.py\", line 30, in embed_query\n",
      "    return self.embedding_model.encode([text])[0]\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain/vectorstores/faiss.py\", line 326, in similarity_search\n",
      "    docs_and_scores = self.similarity_search_with_score(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain/vectorstores/faiss.py\", line 267, in similarity_search_with_score\n",
      "    embedding = self.embedding_function(query)\n",
      "KeyboardInterrupt\n",
      "  File \"/tmp/ipykernel_31150/779960508.py\", line 30, in embed_query\n",
      "    return self.embedding_model.encode([text])[0]\n",
      "  File \"/tmp/ipykernel_31150/4212614069.py\", line 3, in classify\n",
      "    return vdb.similarity_search(item_name, k=1)[0].metadata['category']\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/text2vec/sentence_model.py\", line 177, in encode\n",
      "    embeddings = self.get_sentence_embeddings(\n",
      "  File \"/tmp/ipykernel_31150/4212614069.py\", line 3, in classify\n",
      "    return vdb.similarity_search(item_name, k=1)[0].metadata['category']\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain/vectorstores/faiss.py\", line 326, in similarity_search\n",
      "    docs_and_scores = self.similarity_search_with_score(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain/vectorstores/faiss.py\", line 267, in similarity_search_with_score\n",
      "    embedding = self.embedding_function(query)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/text2vec/sentence_model.py\", line 102, in get_sentence_embeddings\n",
      "    model_output = self.bert(input_ids, attention_mask, token_type_ids, output_hidden_states=True)\n",
      "  File \"/tmp/ipykernel_31150/779960508.py\", line 30, in embed_query\n",
      "    return self.embedding_model.encode([text])[0]\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/pytorch_utils.py\", line 239, in apply_chunking_to_forward\n",
      "    return forward_fn(*input_tensors)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain/vectorstores/faiss.py\", line 326, in similarity_search\n",
      "    docs_and_scores = self.similarity_search_with_score(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 552, in feed_forward_chunk\n",
      "    layer_output = self.output(intermediate_output, attention_output)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/text2vec/sentence_model.py\", line 177, in encode\n",
      "    embeddings = self.get_sentence_embeddings(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 1022, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain/vectorstores/faiss.py\", line 267, in similarity_search_with_score\n",
      "    embedding = self.embedding_function(query)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/text2vec/sentence_model.py\", line 102, in get_sentence_embeddings\n",
      "    model_output = self.bert(input_ids, attention_mask, token_type_ids, output_hidden_states=True)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 464, in forward\n",
      "    hidden_states = self.dense(hidden_states)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 1022, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 612, in forward\n",
      "    layer_outputs = layer_module(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/text2vec/sentence_model.py\", line 177, in encode\n",
      "    embeddings = self.get_sentence_embeddings(\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/text2vec/sentence_model.py\", line 102, in get_sentence_embeddings\n",
      "    model_output = self.bert(input_ids, attention_mask, token_type_ids, output_hidden_states=True)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 497, in forward\n",
      "    self_attention_outputs = self.attention(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 286, in forward\n",
      "    mixed_query_layer = self.query(hidden_states)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 1022, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 427, in forward\n",
      "    self_outputs = self.self(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 612, in forward\n",
      "    layer_outputs = layer_module(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 539, in forward\n",
      "    layer_output = apply_chunking_to_forward(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/pytorch_utils.py\", line 239, in apply_chunking_to_forward\n",
      "    return forward_fn(*input_tensors)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 551, in feed_forward_chunk\n",
      "    intermediate_output = self.intermediate(attention_output)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 451, in forward\n",
      "    hidden_states = self.dense(hidden_states)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 612, in forward\n",
      "    layer_outputs = layer_module(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 539, in forward\n",
      "    layer_output = apply_chunking_to_forward(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/pytorch_utils.py\", line 239, in apply_chunking_to_forward\n",
      "    return forward_fn(*input_tensors)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 552, in feed_forward_chunk\n",
      "    layer_output = self.output(intermediate_output, attention_output)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 464, in forward\n",
      "    hidden_states = self.dense(hidden_states)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "p = Pool(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4f45ad-0b42-45cd-8531-09e1ea58af94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "ba479f98-4d13-4ee4-a8fe-78a4fbc5df24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.9 ms ± 1.08 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "aa030a7e-6630-4426-adff-5257b5b87bce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='FlexFit 運動遮陽帽 - 融熱黑', metadata={'category': '運動機能服飾', 'sample': 'FlexFit 運動遮陽帽 - 融熱黑', 'cs': '運動機能服飾-FlexFit 運動遮陽帽 - 融熱黑'}),\n",
       "  300.34512)]"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vdb.similarity_search_with_score([item_name, item_name], k=1)#[0][0].metadata['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa1c32e-a597-46a2-9618-99555114d7de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05697a09-4c4e-48e3-9362-107d5852f06f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "8cfcf17d-6177-4b9d-83b0-684d66706146",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-08-03 17:48:12.448\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtext2vec.sentence_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m76\u001b[0m - \u001b[34m\u001b[1mUse device: cpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "match_col = 'category' # cs, sample, category\n",
    "docs = list(map(lambda x: Document(page_content=x[1][match_col], metadata=x[1]), df.iterrows()))\n",
    "vdb = FAISS.from_documents(docs, EmbeddingModel(), normalize_L2=False, distance_strategy=DistanceStrategy.COSINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebee58e5-4120-4241-9d40-4511a69f98b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6da04a-5d03-4430-8178-cb158fa33cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "493c8a99-72ff-4757-9d9f-485efc52e87b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def classify(item_name):\n",
    "    # return vdb.similarity_search_with_score(item_name, k=1)[0][0].metadata['category']\n",
    "    return vdb.similarity_search(item_name, k=1)[0].metadata['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "1a44111f-e078-4893-a34f-50eb9105e6a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432 ms ± 48.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "classify(test['item_name'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae3affd-4aa3-43c7-b6e1-ac93b62f47ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "bb3b63e2-e96c-4958-b561-b4cdefdcf77f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='現做咖啡飲品', metadata={'category': '現做咖啡飲品', 'sample': '全家特濃拿鐵', 'cs': '現做咖啡飲品-全家特濃拿鐵'})"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "dc341876-7301-448d-b437-09bb40bffb92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = df_samples.sample(10000)\n",
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8697b74c-be43-474f-9b65-1eba702af449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_type</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>684518</th>\n",
       "      <td>RASTO RK8 摺疊收納伸縮式充電風扇-綠</td>\n",
       "      <td>3C類</td>\n",
       "      <td>桌機/筆電/平板</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456025</th>\n",
       "      <td>Little SiS. 現+預 小夏日🍧 ＃1973 質感</td>\n",
       "      <td>3C類</td>\n",
       "      <td>手機/通訊/週邊</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977661</th>\n",
       "      <td>防蚊貼片 可愛 防蚊 驅蚊神器 防蚊片 防蚊植物 嬰兒防蚊貼</td>\n",
       "      <td>日用百貨類</td>\n",
       "      <td>家庭清潔用品</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507626</th>\n",
       "      <td>0652023052200106</td>\n",
       "      <td>3C類</td>\n",
       "      <td>手機/通訊/週邊</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615628</th>\n",
       "      <td>琨蒂絲蕾絲長統彈性絲襪-黑</td>\n",
       "      <td>服飾鞋包類</td>\n",
       "      <td>流行鞋襪</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97078</th>\n",
       "      <td>【MUJI 無印良品】棉圈絨可剪裁小浴巾/中厚型/可吊掛/煙</td>\n",
       "      <td>洗浴清潔/保養類</td>\n",
       "      <td>美容保養</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833983</th>\n",
       "      <td>【日本旭川】AIRFit氧活力極致涼感支撐空氣坐墊-1人座-</td>\n",
       "      <td>3C類</td>\n",
       "      <td>週邊/耗材</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987717</th>\n",
       "      <td>【現貨免運】珊瑚絨抹布 廚房清潔 抹布 去汙抹布 擦車布 洗</td>\n",
       "      <td>日用百貨類</td>\n",
       "      <td>家庭清潔用品</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545088</th>\n",
       "      <td>【Hush Puppies】女裝 T恤 經典立體品牌刺繡短袖</td>\n",
       "      <td>服飾鞋包類</td>\n",
       "      <td>女裝</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339695</th>\n",
       "      <td>Scotch OPP文具膠帶</td>\n",
       "      <td>書本/文教用品類</td>\n",
       "      <td>文教用品</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               item_name item_type  category\n",
       "684518          RASTO RK8 摺疊收納伸縮式充電風扇-綠        3C類  桌機/筆電/平板\n",
       "456025    Little SiS. 現+預 小夏日🍧 ＃1973 質感        3C類  手機/通訊/週邊\n",
       "977661   防蚊貼片 可愛 防蚊 驅蚊神器 防蚊片 防蚊植物 嬰兒防蚊貼      日用百貨類    家庭清潔用品\n",
       "507626                 0652023052200106        3C類  手機/通訊/週邊\n",
       "615628                    琨蒂絲蕾絲長統彈性絲襪-黑      服飾鞋包類      流行鞋襪\n",
       "...                                  ...       ...       ...\n",
       "97078    【MUJI 無印良品】棉圈絨可剪裁小浴巾/中厚型/可吊掛/煙   洗浴清潔/保養類      美容保養\n",
       "833983   【日本旭川】AIRFit氧活力極致涼感支撐空氣坐墊-1人座-        3C類     週邊/耗材\n",
       "987717   【現貨免運】珊瑚絨抹布 廚房清潔 抹布 去汙抹布 擦車布 洗      日用百貨類    家庭清潔用品\n",
       "545088   【Hush Puppies】女裝 T恤 經典立體品牌刺繡短袖      服飾鞋包類        女裝\n",
       "1339695                  Scotch OPP文具膠帶   書本/文教用品類      文教用品\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "42450882-396b-44fc-aadc-03273faa369b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[432], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict_cs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassify\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mitem_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#test['item_name'].apply(classify)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test['predict_category'] = p.map(classify, test['item_name']) #test['item_name'].apply(classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd036de-777d-4b2c-91e5-318dd9e498b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a69d60-e179-441d-af67-c7def8ae71ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy_score(test['category'], test['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5729bbc2-3317-4f7d-a190-c7ec217cddbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy_score(test['category'], test['predict_cs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5f8276-ec2c-4c78-9d93-fba5741035df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum(test['predict'] != test['predict_cs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e4e83a-725e-44b4-95d9-1a5648bd096c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classify('無印化妝盒')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38ce9ab-9519-4055-9fc7-8d533b86d0ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55aa786-4bda-4d39-8e46-b63d22908ace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
