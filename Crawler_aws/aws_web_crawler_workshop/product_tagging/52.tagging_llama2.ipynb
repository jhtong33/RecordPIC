{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8bd5a31-f3dc-49d9-abb8-c07e1e6e7c8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UserId': 'AROAV52AN3HJJIZVUDZ2F:SageMaker',\n",
       " 'Account': '407620147666',\n",
       " 'Arn': 'arn:aws:sts::407620147666:assumed-role/role-ap-segemaker-execution-setopdata2.0-t/SageMaker',\n",
       " 'ResponseMetadata': {'RequestId': 'f9894023-72a9-4fb3-b6bf-e97736f61613',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'f9894023-72a9-4fb3-b6bf-e97736f61613',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '467',\n",
       "   'date': 'Wed, 09 Aug 2023 14:32:54 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "boto3.client('sts').get_caller_identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86c41230-48df-4f3c-b6fd-4d5f0ffc2fa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create session using your current creds\n",
    "boto_sts=boto3.client('sts')\n",
    "\n",
    "# Request to assume the role like this, the ARN is the Role's ARN from \n",
    "# the other account you wish to assume. Not your current ARN.\n",
    "stsresponse = boto_sts.assume_role(\n",
    "    RoleArn=\"arn:aws:iam::354925255288:role/test\",\n",
    "    RoleSessionName='newsession'\n",
    ")\n",
    "\n",
    "# Save the details from assumed role into vars\n",
    "newsession_id = stsresponse[\"Credentials\"][\"AccessKeyId\"]\n",
    "newsession_key = stsresponse[\"Credentials\"][\"SecretAccessKey\"]\n",
    "newsession_token = stsresponse[\"Credentials\"][\"SessionToken\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ee5060-d5c8-455f-980e-b73bfe08f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client = boto3.client(\"sagemaker\")\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fee1a256-912f-4a1f-9b41-ac760462c751",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm_client = boto3.client(\n",
    "    'sagemaker',\n",
    "    region_name='us-east-1',\n",
    "    aws_access_key_id=newsession_id,\n",
    "    aws_secret_access_key=newsession_key,\n",
    "    aws_session_token=newsession_token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56139a7a-8d98-40d0-b250-7e919736ec00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smr_client = boto3.client(\n",
    "    'sagemaker-runtime',\n",
    "    region_name='us-east-1',\n",
    "    aws_access_key_id=newsession_id,\n",
    "    aws_secret_access_key=newsession_key,\n",
    "    aws_session_token=newsession_token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e08d5478-816a-4f96-bc61-f6f84d6fc568",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = 'huggingface-pytorch-tgi-inference-2023-08-09-14-15-39-283'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e330fe0c-f38a-4fe1-854b-659d20abaa39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfb3580a-7f8b-46a8-861a-01ff177e9faa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.session.Session(\n",
    "    sagemaker_client=sm_client, \n",
    "    sagemaker_runtime_client=smr_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "55eb0876-828b-493f-80ff-1d803faa0272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import serializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5d1b2613-4452-4825-9e46-cdc91316bc8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import deserializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24d1646-b355-4bde-afbb-9080e40eb3f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5efa1bf8-74d2-4d15-8a6d-55e5bd1d5828",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = sagemaker.predictor.Predictor(\n",
    "    endpoint_name=endpoint_name, \n",
    "    sagemaker_session=sagemaker_session, \n",
    "    serializer=serializers.JSONSerializer(),\n",
    "    deserializers=deserializers.JSONDeserializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9f1dc07b-45e8-411c-9126-b9c6c10996ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_llama2_prompt(messages):\n",
    "    startPrompt = \"<s>[INST] \"\n",
    "    endPrompt = \" [/INST]\"\n",
    "    conversation = []\n",
    "    for index, message in enumerate(messages):\n",
    "        if message[\"role\"] == \"system\" and index == 0:\n",
    "            conversation.append(f\"<<SYS>>\\n{message['content']}\\n<</SYS>>\\n\\n\")\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            conversation.append(message[\"content\"].strip())\n",
    "        else:\n",
    "            conversation.append(f\" [/INST] {message.content}</s><s>[INST] \")\n",
    "\n",
    "    return startPrompt + \"\".join(conversation) + endPrompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "11f18675-5429-41c4-9f76-88b3c5a636b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruction = '''\n",
    "Assign appropriate labels/tags to the product as \"tags\", in flavor, brand, key ingredient, and package size \n",
    "(if applicable), etc.  \n",
    "\n",
    "product: {product}\n",
    "\n",
    "1. Return the results in JSON format with the following key: \"tags\".\n",
    "2. Replied answer should be as diverse as possible.\n",
    "3. Do not repeat answers.\n",
    "4. Reply in Taiwan Chinese.\n",
    "5. Please avoid choosing duplicate tags.\n",
    "6. Your tags shall be no more than {max_tags}.\n",
    "7. Reply tag json only, no more information.\n",
    "\n",
    "The json result is: \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "60e02a9c-61aa-4b4a-81c3-31d948e0eb23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "  { \"role\": \"system\",\"content\": instruction.format(product='統一蜜豆奶', max_tags=4)}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b76269e3-4d03-426d-8943-6389dced7157",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '\\nAssign appropriate labels/tags to the product as \"tags\", in flavor, brand, key ingredient, and package size \\n(if applicable), etc.  \\n\\nproduct: 統一蜜豆奶\\n\\n1. Return the results in JSON format with the following key: \"tags\".\\n2. Replied answer should be as diverse as possible.\\n3. Do not repeat answers.\\n4. Reply in Taiwan Chinese.\\n5. Please avoid choosing duplicate tags.\\n6. Your tags shall be no more than 4.\\n7. Reply tag json only, no more information.\\n\\nThe json result is: \\n'}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a3dcdf5f-fd2b-4b3d-8787-47ee30f650a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\n",
      "\"tags\": [\n",
      "\"蜜豆奶\",\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define question and add to messages\n",
    "# instruction = \"What are some cool ideas to do in the summer?\"\n",
    "# messages.append({\"role\": \"user\", \"content\": instruction})\n",
    "prompt = build_llama2_prompt(messages)\n",
    "\n",
    "# chat = llm.predict({\"inputs\": json.dumps(prompt)})\n",
    "chat = llm.predict({\"inputs\":prompt})\n",
    "print(json.loads(chat)[0][\"generated_text\"][len(prompt):])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3bb233d8-2a1e-4817-aba7-fa7bdc7cff69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\n",
      "\"tags\": [\n",
      "\"蜜豆奶\",\n",
      "\"統一\",\n",
      "\"牛奶\",\n",
      "\"甜點\"\n",
      "]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters for llm\n",
    "payload = {\n",
    "  \"inputs\":  prompt,\n",
    "  \"parameters\": {\n",
    "    \"do_sample\": True,\n",
    "    \"top_p\": 0.6,\n",
    "    \"temperature\": 0.01,\n",
    "    \"top_k\": 50,\n",
    "    \"max_new_tokens\": 100,\n",
    "    \"repetition_penalty\": 1.03,\n",
    "    \"stop\": [\"</s>\"]\n",
    "  }\n",
    "}\n",
    "\n",
    "# send request to endpoint\n",
    "response = llm.predict(payload)\n",
    "chat = json.loads(response)\n",
    "print(chat[0][\"generated_text\"][len(prompt):])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2296877-2790-4fde-9620-f103899218ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e040dbb2-f736-4929-af17-e5d3567a5803",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
