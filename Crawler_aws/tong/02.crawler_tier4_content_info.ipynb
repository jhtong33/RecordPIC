{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "930e74f7-528a-4ce1-b9c4-202b61323014",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded plugins: dkms-build-requires, extras_suggestions, langpacks, priorities,\n",
      "              : update-motd, versionlock\n",
      "amzn2-core                                               | 3.7 kB     00:00     \n",
      "https://download.docker.com/linux/centos/2/x86_64/stable/repodata/repomd.xml: [Errno 14] HTTPS Error 404 - Not Found\n",
      "Trying other mirror.\n",
      "neuron                                                   | 2.9 kB     00:00     \n",
      "61 packages excluded due to repository priority protections\n",
      "Package xorg-x11-server-Xvfb-1.20.4-22.amzn2.x86_64 already installed and latest version\n",
      "Nothing to do\n",
      "Requirement already satisfied: scrapy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.10.0)\n",
      "Requirement already satisfied: Twisted>=18.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy) (22.10.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy) (41.0.2)\n",
      "Requirement already satisfied: cssselect>=0.9.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy) (1.2.0)\n",
      "Requirement already satisfied: itemloaders>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy) (1.1.0)\n",
      "Requirement already satisfied: parsel>=1.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy) (1.8.1)\n",
      "Requirement already satisfied: pyOpenSSL>=21.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy) (23.2.0)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy) (1.6.2)\n",
      "Requirement already satisfied: service-identity>=18.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy) (23.1.0)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy) (2.1.2)\n",
      "Requirement already satisfied: zope.interface>=5.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy) (6.0)\n",
      "Requirement already satisfied: protego>=0.1.15 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy) (0.3.0)\n",
      "Requirement already satisfied: itemadapter>=0.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy) (0.8.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy) (68.0.0)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy) (21.3)\n",
      "Requirement already satisfied: tldextract in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy) (3.4.4)\n",
      "Requirement already satisfied: lxml>=4.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy) (4.9.3)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy) (2.0.7)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from cryptography>=36.0.0->scrapy) (1.15.1)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from itemloaders>=1.0.1->scrapy) (1.0.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from service-identity>=18.1.0->scrapy) (23.1.0)\n",
      "Requirement already satisfied: pyasn1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from service-identity>=18.1.0->scrapy) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from service-identity>=18.1.0->scrapy) (0.3.0)\n",
      "Requirement already satisfied: constantly>=15.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Twisted>=18.9.0->scrapy) (15.1.0)\n",
      "Requirement already satisfied: incremental>=21.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Twisted>=18.9.0->scrapy) (22.10.0)\n",
      "Requirement already satisfied: Automat>=0.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Twisted>=18.9.0->scrapy) (22.10.0)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Twisted>=18.9.0->scrapy) (21.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Twisted>=18.9.0->scrapy) (4.7.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging->scrapy) (3.0.9)\n",
      "Requirement already satisfied: idna in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tldextract->scrapy) (3.4)\n",
      "Requirement already satisfied: requests>=2.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tldextract->scrapy) (2.31.0)\n",
      "Requirement already satisfied: requests-file>=1.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tldextract->scrapy) (1.5.1)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tldextract->scrapy) (3.12.2)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Automat>=0.8.0->Twisted>=18.9.0->scrapy) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->scrapy) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.1.0->tldextract->scrapy) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.1.0->tldextract->scrapy) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.1.0->tldextract->scrapy) (2023.5.7)\n",
      "Requirement already satisfied: fake_useragent in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.2.1)\n",
      "Requirement already satisfied: scrapy-selenium in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.0.7)\n",
      "Requirement already satisfied: scrapy>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy-selenium) (2.10.0)\n",
      "Requirement already satisfied: selenium>=3.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy-selenium) (4.9.1)\n",
      "Requirement already satisfied: Twisted>=18.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy>=1.0.0->scrapy-selenium) (22.10.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy>=1.0.0->scrapy-selenium) (41.0.2)\n",
      "Requirement already satisfied: cssselect>=0.9.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy>=1.0.0->scrapy-selenium) (1.2.0)\n",
      "Requirement already satisfied: itemloaders>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy>=1.0.0->scrapy-selenium) (1.1.0)\n",
      "Requirement already satisfied: parsel>=1.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy>=1.0.0->scrapy-selenium) (1.8.1)\n",
      "Requirement already satisfied: pyOpenSSL>=21.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy>=1.0.0->scrapy-selenium) (23.2.0)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy>=1.0.0->scrapy-selenium) (1.6.2)\n",
      "Requirement already satisfied: service-identity>=18.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy>=1.0.0->scrapy-selenium) (23.1.0)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy>=1.0.0->scrapy-selenium) (2.1.2)\n",
      "Requirement already satisfied: zope.interface>=5.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy>=1.0.0->scrapy-selenium) (6.0)\n",
      "Requirement already satisfied: protego>=0.1.15 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy>=1.0.0->scrapy-selenium) (0.3.0)\n",
      "Requirement already satisfied: itemadapter>=0.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy>=1.0.0->scrapy-selenium) (0.8.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy>=1.0.0->scrapy-selenium) (68.0.0)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy>=1.0.0->scrapy-selenium) (21.3)\n",
      "Requirement already satisfied: tldextract in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy>=1.0.0->scrapy-selenium) (3.4.4)\n",
      "Requirement already satisfied: lxml>=4.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy>=1.0.0->scrapy-selenium) (4.9.3)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scrapy>=1.0.0->scrapy-selenium) (2.0.7)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from selenium>=3.9.0->scrapy-selenium) (1.26.14)\n",
      "Requirement already satisfied: trio~=0.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from selenium>=3.9.0->scrapy-selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from selenium>=3.9.0->scrapy-selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from selenium>=3.9.0->scrapy-selenium) (2023.5.7)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from cryptography>=36.0.0->scrapy>=1.0.0->scrapy-selenium) (1.15.1)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from itemloaders>=1.0.1->scrapy>=1.0.0->scrapy-selenium) (1.0.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from service-identity>=18.1.0->scrapy>=1.0.0->scrapy-selenium) (23.1.0)\n",
      "Requirement already satisfied: pyasn1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from service-identity>=18.1.0->scrapy>=1.0.0->scrapy-selenium) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from service-identity>=18.1.0->scrapy>=1.0.0->scrapy-selenium) (0.3.0)\n",
      "Requirement already satisfied: sortedcontainers in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from trio~=0.17->selenium>=3.9.0->scrapy-selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from trio~=0.17->selenium>=3.9.0->scrapy-selenium) (3.4)\n",
      "Requirement already satisfied: outcome in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from trio~=0.17->selenium>=3.9.0->scrapy-selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from trio~=0.17->selenium>=3.9.0->scrapy-selenium) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from trio~=0.17->selenium>=3.9.0->scrapy-selenium) (1.1.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from trio-websocket~=0.9->selenium>=3.9.0->scrapy-selenium) (1.2.0)\n",
      "Requirement already satisfied: constantly>=15.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Twisted>=18.9.0->scrapy>=1.0.0->scrapy-selenium) (15.1.0)\n",
      "Requirement already satisfied: incremental>=21.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Twisted>=18.9.0->scrapy>=1.0.0->scrapy-selenium) (22.10.0)\n",
      "Requirement already satisfied: Automat>=0.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Twisted>=18.9.0->scrapy>=1.0.0->scrapy-selenium) (22.10.0)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Twisted>=18.9.0->scrapy>=1.0.0->scrapy-selenium) (21.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Twisted>=18.9.0->scrapy>=1.0.0->scrapy-selenium) (4.7.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from urllib3[socks]<3,>=1.26->selenium>=3.9.0->scrapy-selenium) (1.7.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging->scrapy>=1.0.0->scrapy-selenium) (3.0.9)\n",
      "Requirement already satisfied: requests>=2.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tldextract->scrapy>=1.0.0->scrapy-selenium) (2.31.0)\n",
      "Requirement already satisfied: requests-file>=1.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tldextract->scrapy>=1.0.0->scrapy-selenium) (1.5.1)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tldextract->scrapy>=1.0.0->scrapy-selenium) (3.12.2)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Automat>=0.8.0->Twisted>=18.9.0->scrapy>=1.0.0->scrapy-selenium) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->scrapy>=1.0.0->scrapy-selenium) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.1.0->tldextract->scrapy>=1.0.0->scrapy-selenium) (3.2.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium>=3.9.0->scrapy-selenium) (0.14.0)\n",
      "Requirement already satisfied: selenium==4.9.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (4.9.1)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from selenium==4.9.1) (1.26.14)\n",
      "Requirement already satisfied: trio~=0.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from selenium==4.9.1) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from selenium==4.9.1) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from selenium==4.9.1) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from trio~=0.17->selenium==4.9.1) (23.1.0)\n",
      "Requirement already satisfied: sortedcontainers in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from trio~=0.17->selenium==4.9.1) (2.4.0)\n",
      "Requirement already satisfied: idna in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from trio~=0.17->selenium==4.9.1) (3.4)\n",
      "Requirement already satisfied: outcome in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from trio~=0.17->selenium==4.9.1) (1.2.0)\n",
      "Requirement already satisfied: sniffio in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from trio~=0.17->selenium==4.9.1) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from trio~=0.17->selenium==4.9.1) (1.1.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from trio-websocket~=0.9->selenium==4.9.1) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from urllib3[socks]<3,>=1.26->selenium==4.9.1) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium==4.9.1) (0.14.0)\n",
      "Requirement already satisfied: boto3==1.28.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.28.5)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3==1.28.5) (1.31.10)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3==1.28.5) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3==1.28.5) (0.6.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.32.0,>=1.31.5->boto3==1.28.5) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.32.0,>=1.31.5->boto3==1.28.5) (1.26.14)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.5->boto3==1.28.5) (1.16.0)\n",
      "Requirement already satisfied: crochet in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.1.1)\n",
      "Requirement already satisfied: Twisted>=16.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from crochet) (22.10.0)\n",
      "Requirement already satisfied: wrapt in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from crochet) (1.15.0)\n",
      "Requirement already satisfied: zope.interface>=4.4.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Twisted>=16.0->crochet) (6.0)\n",
      "Requirement already satisfied: constantly>=15.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Twisted>=16.0->crochet) (15.1.0)\n",
      "Requirement already satisfied: incremental>=21.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Twisted>=16.0->crochet) (22.10.0)\n",
      "Requirement already satisfied: Automat>=0.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Twisted>=16.0->crochet) (22.10.0)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Twisted>=16.0->crochet) (21.0.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Twisted>=16.0->crochet) (23.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Twisted>=16.0->crochet) (4.7.1)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Automat>=0.8.0->Twisted>=16.0->crochet) (1.16.0)\n",
      "Requirement already satisfied: idna>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from hyperlink>=17.1.1->Twisted>=16.0->crochet) (3.4)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from zope.interface>=4.4.2->Twisted>=16.0->crochet) (68.0.0)\n",
      "Requirement already satisfied: awslambdaric in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.0.6)\n",
      "Requirement already satisfied: simplejson==3.17.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from awslambdaric) (3.17.2)\n",
      "Requirement already satisfied: botocore==1.31.10 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.31.10)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore==1.31.10) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore==1.31.10) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore==1.31.10) (1.26.14)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.31.10) (1.16.0)\n",
      "Loaded plugins: dkms-build-requires, extras_suggestions, langpacks, priorities,\n",
      "              : update-motd, versionlock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://download.docker.com/linux/centos/2/x86_64/stable/repodata/repomd.xml: [Errno 14] HTTPS Error 404 - Not Found\n",
      "Trying other mirror.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 packages excluded due to repository priority protections\n",
      "Package atk-2.22.0-3.amzn2.0.2.x86_64 already installed and latest version\n",
      "Package 1:cups-libs-1.6.3-51.amzn2.0.2.x86_64 already installed and latest version\n",
      "Package gtk3-3.22.30-3.amzn2.x86_64 already installed and latest version\n",
      "Package libXcomposite-0.4.4-4.1.amzn2.0.2.x86_64 already installed and latest version\n",
      "Package alsa-lib-1.1.4.1-2.amzn2.x86_64 already installed and latest version\n",
      "Package libXcursor-1.1.15-1.amzn2.x86_64 already installed and latest version\n",
      "Package libXdamage-1.1.4-4.1.amzn2.0.2.x86_64 already installed and latest version\n",
      "Package libXext-1.3.3-3.amzn2.0.2.x86_64 already installed and latest version\n",
      "Package libXi-1.7.9-1.amzn2.0.2.x86_64 already installed and latest version\n",
      "Package libXrandr-1.5.1-2.amzn2.0.3.x86_64 already installed and latest version\n",
      "Package libXScrnSaver-1.2.2-6.1.amzn2.0.2.x86_64 already installed and latest version\n",
      "Package libXtst-1.2.3-1.amzn2.0.2.x86_64 already installed and latest version\n",
      "Package pango-1.42.4-4.amzn2.x86_64 already installed and latest version\n",
      "Package at-spi2-atk-2.22.0-2.amzn2.0.2.x86_64 already installed and latest version\n",
      "Package libXt-1.1.5-3.amzn2.0.2.x86_64 already installed and latest version\n",
      "Package xorg-x11-server-Xvfb-1.20.4-22.amzn2.x86_64 already installed and latest version\n",
      "Package 1:xorg-x11-xauth-1.0.9-1.amzn2.0.2.x86_64 already installed and latest version\n",
      "Package dbus-glib-0.100-7.2.amzn2.x86_64 already installed and latest version\n",
      "Package dbus-glib-devel-0.100-7.2.amzn2.x86_64 already installed and latest version\n",
      "Nothing to do\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 7233k  100 7233k    0     0  20.1M      0 --:--:-- --:--:-- --:--:-- 20.1M\n",
      "Archive:  /tmp/chromedriver.zip\n",
      "caution: filename not matched:  -y\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  165M  100  165M    0     0  26.9M      0  0:00:06  0:00:06 --:--:-- 32.3M\n",
      "Archive:  /tmp/chrome-linux.zip\n",
      "caution: filename not matched:  -y\n"
     ]
    }
   ],
   "source": [
    "!sudo yum install Xvfb -y -y\n",
    "!pip install scrapy\n",
    "!pip install fake_useragent\n",
    "!pip install scrapy-selenium\n",
    "!pip install selenium==4.9.1\n",
    "!pip install boto3==1.28.5\n",
    "!pip install crochet\n",
    "!pip install awslambdaric\n",
    "!pip install botocore==1.31.10\n",
    "\n",
    "\n",
    "import os\n",
    "cmd = '''\n",
    "sudo yum install atk cups-libs gtk3 libXcomposite alsa-lib libXcursor libXdamage libXext libXi libXrandr libXScrnSaver libXtst pango at-spi2-atk libXt xorg-x11-server-Xvfb xorg-x11-xauth dbus-glib dbus-glib-devel -y\n",
    "'''\n",
    "os.system(cmd)\n",
    "\n",
    "\n",
    "!curl  -Lo \"/tmp/chromedriver.zip\" \"https://chromedriver.storage.googleapis.com/114.0.5735.90/chromedriver_linux64.zip\"\n",
    "!unzip /tmp/chromedriver.zip -d /opt/ -y\n",
    "!sudo ln -sf /opt/chromedriver /usr/local/bin/chromedriver\n",
    "\n",
    "!curl -Lo \"/tmp/chrome-linux.zip\" \"https://www.googleapis.com/download/storage/v1/b/chromium-browser-snapshots/o/Linux_x64%2F1135561%2Fchrome-linux.zip?alt=media\"\n",
    "!unzip /tmp/chrome-linux.zip -d /opt/ -y\n",
    "!sudo ln -sf /opt/chrome-linux/chrome /usr/local/bin/chrome\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b05ae87e-9db0-4a1c-bbd4-b1c1919eba27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lrwxrwxrwx 1 root root 24 Aug 25 02:38 /usr/local/bin/chrome -> /opt/chrome-linux/chrome\n",
      "lrwxrwxrwx 1 root root 17 Aug 25 02:38 /usr/local/bin/chromedriver -> /opt/chromedriver\n",
      "-rwxr-xr-x 1 ec2-user ec2-user 358375680 Apr 25 22:16 /opt/chrome-linux/chrome\n"
     ]
    }
   ],
   "source": [
    "!ls -al /usr/local/bin/chrome\n",
    "!ls -al /usr/local/bin/chromedriver\n",
    "!ls -al /opt/chrome-linux/chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dee734bb-5db7-4125-a4b9-0a646285bd6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import botocore\n",
    "from fake_useragent import UserAgent\n",
    "import boto3\n",
    "from scrapy.crawler import CrawlerRunner\n",
    "from scrapy.utils.project import get_project_settings\n",
    "from crochet import setup\n",
    "import threading\n",
    "# from momoshop_link import MomoshopSpider\n",
    "\n",
    "# Initialize Crochet\n",
    "setup()\n",
    "\n",
    "ua = UserAgent()\n",
    "CHROME_BROWSER_PATH = '/usr/local/bin/chrome'\n",
    "region = 'ap-northeast-1'\n",
    "sqs = boto3.client('sqs', region_name=region, config=botocore.client.Config(max_pool_connections=500))\n",
    "queue_tier4_links = 'https://sqs.ap-northeast-1.amazonaws.com/407620147666/aws_crawler_tier4_links.fifo'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148e1651-90fb-421e-a884-46dba60d0f31",
   "metadata": {
    "tags": []
   },
   "source": [
    "### spiders.momoshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23afa8eb-a566-4a05-ba99-ae8fc68a2014",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import threading\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "from scrapy import Selector\n",
    "from scrapy_selenium import SeleniumRequest\n",
    "import botocore\n",
    "import scrapy\n",
    "from fake_useragent import UserAgent\n",
    "import boto3\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium import webdriver\n",
    "\n",
    "\n",
    "\n",
    "ua = UserAgent()\n",
    "CHROME_BROWSER_PATH = '/usr/local/bin/chrome'\n",
    "sqs = boto3.client('sqs', region_name=region, config=botocore.client.Config(max_pool_connections=500))\n",
    "s3 = boto3.client('s3', region_name=region, config=botocore.client.Config(max_pool_connections=500))\n",
    "region = 'ap-northeast-1'\n",
    "export_to_s3 = 'Off'\n",
    "queue_tier4_content_links =  '\thttps://sqs.ap-northeast-1.amazonaws.com/407620147666/aws_crawler_tier4_links.fifo'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def hash_function(original_string):\n",
    "    # Create a hash object using SHA-256 algorithm\n",
    "    hasher = hashlib.sha256()\n",
    "\n",
    "    # Convert the input string to bytes (required by hashlib)\n",
    "    input_bytes = original_string.encode('utf-8')\n",
    "\n",
    "    # Update the hash object with the input bytes\n",
    "    hasher.update(input_bytes)\n",
    "\n",
    "    # Get the hexadecimal representation of the hash value\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "\n",
    "class MomoshopSpider(scrapy.Spider):\n",
    "    name = \"momoshop\"\n",
    "    allowed_domains = [\"www.momoshop.com.tw\"]\n",
    "    user_agent = ua.random\n",
    "    runner = None\n",
    "    category_links = []\n",
    "    tier = None\n",
    "\n",
    "    def __init__(self, runner=None, **kwargs):\n",
    "        self.runner = runner\n",
    "        super(MomoshopSpider, self).__init__(**kwargs)\n",
    "\n",
    "    def start_requests(self):\n",
    "        # Start the initial request to fetch category links\n",
    "        print(\"Starting start_requests\")\n",
    "        \n",
    "        if self.runner.target_url == \"\":\n",
    "            tier4_content_link = json.loads(self.runner.tier4_content_object['Body'])['tier4_content_link']\n",
    "        else:\n",
    "            tier4_content_link = self.runner.target_url\n",
    "\n",
    "        # tier4_content_link = 'https://www.momoshop.com.tw/goods/GoodsDetail.jsp?i_code=10795343&cid=recitri&oid=BfL&mdiv=category_momoshop-cap_p2-&ctype=B&recomd_id=rgc-hqlk_normal_1692180696_195593'\n",
    "        # self.tier = {'tier1': '個人清潔', 'tier2': '洗髮精/潤護髮', 'tier3': '精選品牌', 'tier4': 'FineToday日系髮品'}\n",
    "\n",
    "\n",
    "        headers = {\"Host\": urlparse(tier4_content_link).netloc,\n",
    "                   'Accept-Encoding': 'gzip, deflate, br',\n",
    "                   'Accept-Language': 'en-US,en;q=0.9,zh-TW;q=0.8,zh;q=0.7,zh-CN;q=0.6,ja;q=0.5',\n",
    "                   'Sec-Fetch-Dest': 'document',\n",
    "                   'Sec-Fetch-Mode': 'navigate',\n",
    "                   'Sec-Fetch-Site': 'none',\n",
    "                   'Upgrade-Insecure-Requests': '1',\n",
    "                   \"Referer\": \"https://www.momoshop.com.tw/main/Main.jsp\",\n",
    "                   \"User-Agent\": ua.random}\n",
    "        print(f'tier4_content_link: {tier4_content_link}')\n",
    "        # https://www.momoshop.com.tw/goods/GoodsDetail.jsp?i_code=10670127&str_category_code=1501202193&ctype=B&Area=DgrpCategory&sourcePageType=4\n",
    "        yield SeleniumRequest(url=tier4_content_link,\n",
    "                              headers=headers,\n",
    "                              callback=self.parse,\n",
    "                              wait_time=15,\n",
    "                              errback=self.error_handle,\n",
    "                              wait_until=ec.presence_of_element_located((By.XPATH, \"//*\"))\n",
    "                              )\n",
    "        \n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def set_all_tier(response):\n",
    "        # The original class array => ['Home', '家電', '飲水設備', '\\n            ', '本月主打', '元山★開館慶下殺']\n",
    "        tier_array = \"|\".join(response.css(\"#bt_2_layout_NAV ul li ::text\").getall()).replace(\" \", \"\").replace(\"\\n\", \"\").replace(\"||\", \"|\").split(\"|\")\n",
    "        tier_array.pop(0)\n",
    "        print(tier_array)\n",
    "        return tier_array\n",
    "\n",
    "#     @staticmethod\n",
    "#     def construct_s3_tier_folder(content_tier: dict):\n",
    "#         # Construct the base folder path\n",
    "#         base_path = \"content\"\n",
    "\n",
    "#         # Create the base folder if it doesn't exist\n",
    "#         if base_path:\n",
    "#             s3.put_object(Bucket=s3_crawler_content_folder, Key=f\"{base_path}/\")\n",
    "\n",
    "#         # Construct the folder structure based on the tiers\n",
    "#         for key, value in content_tier.items():\n",
    "\n",
    "#             folder_name = value.strip('/')\n",
    "#             folder_path = f\"{base_path}/{folder_name}\"\n",
    "\n",
    "#             # Create the folder if it doesn't exist\n",
    "#             s3.put_object(Bucket=s3_crawler_content_folder, Key=f\"{folder_path}/\")\n",
    "\n",
    "#             # Set the current folder path as the base path for the next iteration\n",
    "#             base_path = folder_path\n",
    "\n",
    "    def error_handle(self, error):\n",
    "        print(error)\n",
    "        self.runner.timeout = True\n",
    "\n",
    "    def parse(self, response, **kwargs):\n",
    "        try:\n",
    "            # Parse the main category page and extract links to individual product pages\n",
    "            print(f\"Starting to parse\")\n",
    "            selector = Selector(response)\n",
    "            \n",
    "            # print(response.request.meta)\n",
    "            # driver = response.request.meta['driver']\n",
    "            \n",
    "            options = webdriver.ChromeOptions()\n",
    "            options.binary_location = \"/opt/chrome-linux/chrome\"\n",
    "            options.add_argument(\"--headless\")\n",
    "            options.add_argument(\"--no-sandbox\")\n",
    "            options.add_argument(\"--single-process\")\n",
    "            options.add_argument(\"--disable-dev-shm-usage\")\n",
    "            options.add_argument(\"blink-settings=imagesEnabled=false\")\n",
    "            options.add_argument(\"--remote-debugging-port=9222\")\n",
    "            options.add_argument(\"--no-zygote\")\n",
    "            options.add_argument(\"--disable-gpu\")\n",
    "            options.add_argument(\"--disable-dev-tools\")\n",
    "    \n",
    "            driver = webdriver.Chrome(executable_path = '/usr/local/bin/chromedriver', chrome_options=options)\n",
    "            driver.get(response.url)\n",
    "\n",
    "            content_info_tier = self.set_all_tier(response)\n",
    "            # self.construct_s3_tier_folder(content_info_tier)\n",
    "\n",
    "            # 品牌名稱\n",
    "            item_brand = selector.css(\"#webBrand ::text\").get(None)\n",
    "\n",
    "            # 市售價\n",
    "            market_price = None\n",
    "\n",
    "            # 促銷價\n",
    "            promotional_price = None\n",
    "\n",
    "            # 品牌名稱\n",
    "            discounted_price = None\n",
    "\n",
    "            # 折扣後價格\n",
    "            price_list = selector.css(\".prdPrice li\")\n",
    "\n",
    "            for price in price_list:\n",
    "                if price.css(\"li ::text\").get() == '市售價':\n",
    "                    market_price = int(price.css(\"li .seoPrice ::text\").get().replace(',', ''))\n",
    "                if price.css(\"li ::text\").get() == '促銷價':\n",
    "                    promotional_price = int(price.css(\"li .seoPrice ::text\").get().replace(',', ''))\n",
    "                if price.css(\"li ::text\").get() == '折扣後價格':\n",
    "                    discounted_price = int(price.css(\"li .seoPrice ::text\").get().replace(',', ''))\n",
    "            \n",
    "            # <span id=\"osmGoodsName\"> <a class=\"productName\" href=\"/search/searchShop.jsp?keyword=%E6%9E%97%E5%85%A7&amp;brand=%E6%9E%97%E5%85%A7&amp;brandNo=20160808160045893\">林內</a> 台爐式內焰二口爐輕量爐架(RTS-N201S原廠安裝)</span>\n",
    "            # 商品名稱\n",
    "            item_name = \"\".join(selector.css(\"#osmGoodsName ::text\").extract()).strip()\n",
    "            # 活動\n",
    "            activity = \"\".join(selector.css(\".ineventArea li ::text\").extract()).replace(' ', '').replace('\\n', '')\n",
    "            print(activity)\n",
    "            # 商品規格\n",
    "            item_spec = {}\n",
    "            for item_spec_attribute in selector.css(\"#attributesTable tr\"):\n",
    "                item_spec[item_spec_attribute.css(\"th ::text\").get()] = str(item_spec_attribute.css(\"td ::text\").get()).replace(' ', '')\n",
    "                \n",
    "            # 相關類別\n",
    "            related_category_list = []\n",
    "            for related_category_elements in selector.css(\".related_category dl\"):\n",
    "                if related_category_elements.css(\"dl::attr(class)\").get() != \"brandTxt\":\n",
    "                    related_category_list.append(\"|\".join(related_category_elements.css(\"dd ::text\").getall()).replace(\"\\\\\\\\\", \"\\\\\"))\n",
    "            # 商品評價\n",
    "            goods_commend = {\"count\": int(selector.css('.goodsCommendLi span::attr(goodscount)').get(\"5\").replace(\",\", \"\"))}\n",
    "\n",
    "            # 評論內容\n",
    "            review_card_list = []\n",
    "\n",
    "            # If there's any goods commend then fetch all of them\n",
    "            if goods_commend[\"count\"] > 0:\n",
    "                # Send the javascript to click\n",
    "                js_code = f\"document.querySelector('.goodsCommendLi').click();\"  # Click the page number\n",
    "                driver.execute_script(js_code)\n",
    "\n",
    "                # Wait for the new content to load after the click\n",
    "                # Adjust the timeout as needed\n",
    "                # wait = WebDriverWait(driver, 15)\n",
    "                # # # Wait for goods comment is ready for click\n",
    "                # wait.until(ec.presence_of_element_located((By.CSS_SELECTOR, '.reviewCard')))\n",
    "\n",
    "                # Get the updated page source and extract product links\n",
    "                updated_content = driver.page_source\n",
    "                selector = Selector(scrapy.http.HtmlResponse(url=driver.current_url,\n",
    "                                                             body=updated_content,\n",
    "                                                             encoding='utf-8'))\n",
    "\n",
    "                goods_commend[\"indicator_average_value\"] = float(selector.css('.indicatorAvgVal::text').get())\n",
    "\n",
    "                for indicator in selector.css(\".indicator\"):\n",
    "                    if indicator.css(\".indicatorTitle::text\").get() == \"商品品質\":\n",
    "                        goods_commend[\"indicator_quality\"] = float(selector.css('.indicatorNumber::text').get(None))\n",
    "                    if indicator.css(\".indicatorTitle::text\").get() == \"商品符合\":\n",
    "                        goods_commend[\"indicator_accurate\"] = float(selector.css('.indicatorNumber::text').get(None))\n",
    "                    if indicator.css(\".indicatorTitle::text\").get() == \"出貨速度\":\n",
    "                        goods_commend[\"indicator_shipping\"] = float(selector.css('.indicatorNumber::text').get(None))\n",
    "\n",
    "                # Fetch all commends info\n",
    "                # 商品評論統計\n",
    "                goods_commend_info = []\n",
    "                for goods_commend_info_attribute in selector.css(\".SelectorOption\"):\n",
    "                    goods_commend_info.append(\"\".join(goods_commend_info_attribute.css(\"::text\").getall()))\n",
    "                goods_commend[\"goods_commend_info\"] = goods_commend_info\n",
    "\n",
    "                # Fetch the all comments in the first page\n",
    "                self.fetch_goods_commend(selector, review_card_list)\n",
    "                # 上一頁/下一頁\n",
    "                page_control = selector.css('.pageArea dd')\n",
    "                if len(page_control) > 0:  # Has next page\n",
    "                    has_next_page = True\n",
    "                    while has_next_page:\n",
    "                        first_page_control = page_control[0]\n",
    "                        second_page_control = page_control[1] if len(page_control) > 1 else None\n",
    "                        if first_page_control.css('a::text').get() == \"下一頁\":\n",
    "                            # Get the next page index\n",
    "                            page_index = first_page_control.css(\"dd::attr(pageidx)\").get()\n",
    "                            print(f'page_index: {page_index}')\n",
    "                            page_control = self.click_to_next_page(page_index, driver, review_card_list)\n",
    "                        elif second_page_control is None:\n",
    "                            has_next_page = False\n",
    "                        else:\n",
    "                            # Get the next page index\n",
    "                            page_index = second_page_control.css(\"dd::attr(pageidx)\").get()\n",
    "                            print(f'page_index:{page_index}')\n",
    "                            page_control = self.click_to_next_page(page_index, driver, review_card_list)\n",
    "\n",
    "            goods_commend[\"review_card_list\"] = review_card_list\n",
    "\n",
    "            content_info = {'item_brand': item_brand,\n",
    "                            'item_name': item_name,\n",
    "                            'market_price': market_price,\n",
    "                            'promotional_price': promotional_price,\n",
    "                            'discounted_price': discounted_price,\n",
    "                            'activity': activity,\n",
    "                            'data_date': datetime.datetime.now().strftime(\"%Y%m%d\"),\n",
    "                            'item_url': response.url,\n",
    "                            'item_spec': item_spec,\n",
    "                            'related_category_list': related_category_list,\n",
    "                            'goods_commend_indicator_average_value': goods_commend[\"indicator_average_value\"],\n",
    "                            'goods_commend_goods_commend_info': goods_commend[\"goods_commend_info\"],\n",
    "                            'goods_commend_indicator_quality': goods_commend[\"indicator_quality\"],\n",
    "                            'goods_commend_indicator_accurate': goods_commend[\"indicator_accurate\"],\n",
    "                            'goods_commend_indicator_shipping': goods_commend[\"indicator_shipping\"],\n",
    "                            'goods_commend_review_card_list': goods_commend[\"review_card_list\"]\n",
    "                            }\n",
    "            print(content_info)\n",
    "            # Configure tiers\n",
    "            for i in range(0, len(content_info_tier)):\n",
    "                content_info[f'tier{i + 1}'] = content_info_tier[i]\n",
    "\n",
    "            # Send the result json to s3\n",
    "            # hash_id = hash_function(response.url)\n",
    "            # self.send_to_s3(content_info, hash_id)\n",
    "\n",
    "            # output the result in the local\n",
    "            with open('output.json', 'w') as json_file:\n",
    "                json_file.write(json.dumps(content_info, ensure_ascii=False))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "    def click_to_next_page(self, page_index: str, driver, review_card_list):\n",
    "        # Send the javascript to click\n",
    "        js_code = f\"[...document.querySelectorAll('.pageArea a')].find(a => a.textContent.trim() === '{page_index}').click();\"   # Click the page number\n",
    "        driver.execute_script(js_code)\n",
    "\n",
    "        # Get the updated page source and extract product links\n",
    "        updated_content = driver.page_source\n",
    "        updated_selector = Selector(scrapy.http.HtmlResponse(url=driver.current_url,\n",
    "                                                             body=updated_content,\n",
    "                                                             encoding='utf-8'))\n",
    "\n",
    "        self.fetch_goods_commend(updated_selector, review_card_list)\n",
    "        return updated_selector.css('.pageArea dd')\n",
    "\n",
    "    @staticmethod\n",
    "    def fetch_goods_commend(selector: Selector, review_card_list):\n",
    "        for review_card in selector.css('.reviewCard'):\n",
    "            review_card_score = review_card.css(\".RatingStarGroup::attr(score)\").get()\n",
    "            review_card_spec = \"\".join(review_card.css(\".SpecValue ::text\").getall())\n",
    "            review_card_date = review_card.css(\".Info ::text\").get()\n",
    "            review_card_comment = review_card.css(\".CommentContainer ::text\").get()\n",
    "            review_card_list.append({\n",
    "                'review_card_score': review_card_score,\n",
    "                'review_card_spec': review_card_spec,\n",
    "                'review_card_date': review_card_date,\n",
    "                'review_card_comment': review_card_comment\n",
    "            })\n",
    "\n",
    "\n",
    "#     @staticmethod\n",
    "#     def send_to_s3(message, hash_id):\n",
    "#         # Send the message to S3\n",
    "#         try:\n",
    "#             json_file_name = f'{hash_id}.json'\n",
    "\n",
    "#             # Construct the S3 key including the folder name\n",
    "#             s3_key = f'content/{message[\"tier1\"]}/{json_file_name}'\n",
    "\n",
    "#             response = s3.put_object(Bucket=s3_crawler_content_folder, Key=s3_key,\n",
    "#                                      Body=json.dumps(message, ensure_ascii=False))\n",
    "#             # check if it's successful\n",
    "#             if response[\"ResponseMetadata\"][\"HTTPStatusCode\"] != 200:\n",
    "#                 print('Fail')\n",
    "#         except Exception as e:\n",
    "#             print(str(e))\n",
    "\n",
    "\n",
    "    def spider_closed(self):\n",
    "        # Handle the spider closing event\n",
    "        self.runner.timeout = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecb0a207-457d-4e4b-99b6-ff86f9e8631d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to crawl:2023-08-25 02:38:47.603890\n",
      "Starting start_requests\n",
      "tier4_content_link: https://www.momoshop.com.tw/goods/GoodsDetail.jsp?i_code=10795343&cid=recitri&oid=BfL&mdiv=category_momoshop-cap_p2-&ctype=B&recomd_id=rgc-hqlk_normal_1692180696_195593\n",
      "Starting to parse\n",
      "['個人清潔', '洗髮精/潤護髮', '精選品牌', 'FineToday日系髮品']\n",
      "08/23~08/31 結帳9折↘ 滿1件享9折(說明)08/23~08/31 滿888折100↘滿888再折100(說明)\n",
      "page_index: 2\n",
      "page_index:3\n",
      "page_index:4\n",
      "{'item_brand': 'TSUBAKI 思波綺', 'item_name': 'TSUBAKI 思波綺 升級版 瞬亮洗髮/潤髮 490ml(任選1入)', 'market_price': 290, 'promotional_price': 274, 'discounted_price': 246, 'activity': '08/23~08/31\\xa0結帳9折↘\\xa0滿1件享9折(說明)08/23~08/31\\xa0滿888折100↘滿888再折100(說明)', 'data_date': '20230825', 'item_url': 'https://www.momoshop.com.tw/goods/GoodsDetail.jsp?i_code=10795343&cid=recitri&oid=BfL&mdiv=category_momoshop-cap_p2-&ctype=B&recomd_id=rgc-hqlk_normal_1692180696_195593', 'item_spec': {'品牌名稱': 'TSUBAKI思波綺', '香味': '果香', '品牌定位': '沙龍', '包裝組合': '單入組', '功效': '柔亮滑順', '容量': '401~600ml', '適用於': '所有髮質', '產地': '日本'}, 'related_category_list': ['個人清潔|沙龍髮品|洗髮精', '個人清潔|洗髮精/潤護髮|洗髮精', '個人清潔|洗髮精/潤護髮|精選品牌|FineToday日系髮品'], 'goods_commend_indicator_average_value': 4.9, 'goods_commend_goods_commend_info': ['有評論(37)', '有圖/影片(0)', '最佳評論', '5星(70)', '4星(7)', '3星(0)', '2星(0)', '1星(0)'], 'goods_commend_indicator_quality': 4.9, 'goods_commend_indicator_accurate': 4.9, 'goods_commend_indicator_shipping': 4.9, 'goods_commend_review_card_list': [{'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/08/22', 'review_card_comment': '商品品質很好，到貨速度很快\\n常用品'}, {'review_card_score': '4', 'review_card_spec': '規格 : 瞬亮潤澤-洗髮精', 'review_card_date': '2023/08/05', 'review_card_comment': '這款洗髮乳在金門民宿用過, 覺得非常好用, 香及柔順, 記下牌子回來網購, 雖然還沒開封使用, 但應該沒錯, 當時有問民宿闆娘說有調漲, 果然沒錯.'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-潤髮乳', 'review_card_date': '2023/08/02', 'review_card_comment': '潤髮乳的味道好聞，護髮效果好'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮潤澤-洗髮精', 'review_card_date': '2023/07/29', 'review_card_comment': '多次購買 希望多多特價'}, {'review_card_score': '4', 'review_card_spec': '規格 : 瞬亮潤澤-洗髮精', 'review_card_date': '2023/07/28', 'review_card_comment': 'delivery is fast and accurate, product meets expectations, good to go for next round satisfaction is'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/07/26', 'review_card_comment': '洗起來很柔順，味道也很好聞'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/07/23', 'review_card_comment': '送貨速度快，東西好用'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-潤髮乳', 'review_card_date': '2023/07/16', 'review_card_comment': '味道很香效果也不錯哦'}, {'review_card_score': '4', 'review_card_spec': '規格 : 瞬亮潤澤-潤髮乳', 'review_card_date': '2023/07/02', 'review_card_comment': '滑順度讚'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/06/30', 'review_card_comment': '洗髮精味道很聞，洗完後髮質摸起來也很不錯！'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/06/28', 'review_card_comment': '商品包裝很漂亮，味道很好聞。'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/06/21', 'review_card_comment': '香味和紅色Tsubaki很像，洗完頭髮有點蓬鬆，滑順度的話，紅色Tsubaki較佳'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮潤澤-洗髮精', 'review_card_date': '2023/06/19', 'review_card_comment': '洗髮精很好用，一直持續有回購。'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮潤澤-潤髮乳', 'review_card_date': '2023/06/19', 'review_card_comment': '潤髮乳很好用，一直持續回購。'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-潤髮乳', 'review_card_date': '2023/06/12', 'review_card_comment': '用起來很滑順，頭髮不打結'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/06/03', 'review_card_comment': '出貨速度超快，品質優良'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮潤澤-洗髮精', 'review_card_date': '2023/06/02', 'review_card_comment': '趁有優惠促銷來屯貨,還有送贈品,真是划算~'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/06/02', 'review_card_comment': '趁有優惠促銷來屯貨,還有送贈品,真是划算~'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/05/28', 'review_card_comment': '這牌子的護髮非常讚，因此來試試看洗髮精'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/05/19', 'review_card_comment': '味道好聞，包裝好看透明'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-潤髮乳', 'review_card_date': '2023/05/17', 'review_card_comment': '送貨速度快 商品正確 下次會再購買'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮潤澤-洗髮精', 'review_card_date': '2023/05/17', 'review_card_comment': '使用後，頭髮亮澤好梳理'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮潤澤-洗髮精', 'review_card_date': '2023/05/15', 'review_card_comment': '氣味好聞，持續回購的產品'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/04/15', 'review_card_comment': '思波綺瞬亮洗髮精，味道很喜歡，洗後柔順有光澤，再次回購。'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/04/15', 'review_card_comment': '包裝完整，商品符合期待。'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/02/20', 'review_card_comment': '採用日本獨特的產品配方和山茶花精油，透過革新滲透技術，實現「無需等待的0秒沙龍級護髮」。'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/02/19', 'review_card_comment': '價格優惠,品質佳,出貨速度快,會再回購'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/02/15', 'review_card_comment': '味道可以，還沒有使用，如果好用我會持續購買！'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮潤澤-潤髮乳', 'review_card_date': '2023/02/15', 'review_card_comment': '味道可以，還沒有使用，如果好用我會持續購買！'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-潤髮乳', 'review_card_date': '2023/02/15', 'review_card_comment': '味道可以，還沒有使用，如果好用我會持續購買！'}, {'review_card_score': '4.5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/02/09', 'review_card_comment': '送貨速度非常快，東西味道很香！可以！'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮潤澤-潤髮乳', 'review_card_date': '2023/02/07', 'review_card_comment': '洗歡這香氣和柔順感！'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮潤澤-洗髮精', 'review_card_date': '2023/02/05', 'review_card_comment': '商品迅速送達且正確無損。'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮潤澤-洗髮精', 'review_card_date': '2023/02/03', 'review_card_comment': '洗髮精品質非常好，洗了之後頭髮非常柔順，感謝MOMO！'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮潤澤-潤髮乳', 'review_card_date': '2023/02/03', 'review_card_comment': '洗髮精品質非常好，洗了之後頭髮非常柔順，感謝MOMO！'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/01/24', 'review_card_comment': '出貨超快'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮潤澤-洗髮精', 'review_card_date': '2023/01/14', 'review_card_comment': '商品正確，送貨迅速，下次有需要會再購買！'}]}\n",
      "End date and time:2023-08-25 02:39:00.315917\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "class LambdaRunner:\n",
    "    target_url = \"\"\n",
    "    receipt_handle = \"\"\n",
    "    tier4_content_object = None\n",
    "    timeout = False\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.finished = threading.Event()\n",
    "        self.results = []\n",
    "        if url != \"\":\n",
    "            self.target_url = url\n",
    "\n",
    "    def run_spider(self):\n",
    "        # Create a CrawlerRunner with project settings\n",
    "        settings = get_project_settings()\n",
    "        runner = CrawlerRunner(settings)\n",
    "        if self.target_url == \"\":\n",
    "            self.get_tier4_content_url_from_sqs()\n",
    "\n",
    "        # Callback function to handle the spider results\n",
    "        def handle_results(result):\n",
    "            self.results.append(result)\n",
    "\n",
    "            # Check if the spider has finished running\n",
    "            if len(self.results) == 1:\n",
    "                self.finished.set()\n",
    "\n",
    "        # Start the first spider run\n",
    "        deferred = runner.crawl(MomoshopSpider, self)\n",
    "        deferred.addCallback(handle_results)\n",
    "\n",
    "        # Start the reactor\n",
    "        runner.join()\n",
    "\n",
    "    def wait_for_completion(self):\n",
    "        self.finished.wait()\n",
    "\n",
    "    def get_results(self):\n",
    "        return self.results\n",
    "\n",
    "    def get_tier4_content_url_from_sqs(self):\n",
    "        response = sqs.receive_message(\n",
    "            QueueUrl=queue_tier4_content_links,\n",
    "            MaxNumberOfMessages=1,  # Retrieve 10 messages\n",
    "            WaitTimeSeconds=0  # Maximum time to wait for messages (long polling)\n",
    "        )\n",
    "        messages = response.get('Messages', [])\n",
    "        if messages is not None:\n",
    "            self.tier4_content_object = messages[0]\n",
    "        else:\n",
    "            msg = \"All consumed.\"\n",
    "            print(msg)\n",
    "            return msg\n",
    "\n",
    "        # Delete messages from SQS\n",
    "        for message in messages:\n",
    "            sqs.delete_message(\n",
    "                QueueUrl=queue_tier4_content_links,\n",
    "                ReceiptHandle=message['ReceiptHandle']\n",
    "            )\n",
    "\n",
    "\n",
    "def handler(event, context):\n",
    "    try:\n",
    "        # Check if the function was triggered by an HTTP request or Lambda event\n",
    "        print(f\"Starting to crawl:{datetime.datetime.now()}\")\n",
    "        times = 0\n",
    "        if \"statusCode\" not in event:\n",
    "            # If the function was not triggered by retry\n",
    "            runner = LambdaRunner(\"\")\n",
    "            runner.run_spider()\n",
    "            runner.wait_for_completion()\n",
    "            print(f\"End date and time:{datetime.datetime.now()}\")\n",
    "        else:\n",
    "            times = int(event[\"times\"])\n",
    "            if times < 4:\n",
    "                runner = LambdaRunner(event[\"category_link\"])\n",
    "                runner.input_url = event[\"category_link\"]\n",
    "                runner.run_spider()\n",
    "                runner.wait_for_completion()\n",
    "                print(f\"End date and time:{datetime.datetime.now()}\")\n",
    "            else:\n",
    "                print(f'Retry too many times, 429:{event[\"category_link\"]}')\n",
    "                # If the retry count is 4 or more, return an HTTP 429 response indicating Too Many Requests\n",
    "                return {\n",
    "                    'statusCode': 429,\n",
    "                    'body': \"\",\n",
    "                    'times': times,\n",
    "                    \"category_link\": event[\"category_link\"]\n",
    "                }\n",
    "\n",
    "        times = times + 1\n",
    "        if not runner.timeout:\n",
    "            print(\"success\")\n",
    "            # If the LambdaRunner completed successfully, return an HTTP 200 response with the completion details\n",
    "            return {\n",
    "                'statusCode': 200,\n",
    "                'body': 'Completed!',\n",
    "                'times': times\n",
    "            }\n",
    "        else:\n",
    "            print('timeout')\n",
    "            # If the LambdaRunner timed out, return an HTTP 408 response with the category objects\n",
    "            return {\n",
    "                'statusCode': 408,\n",
    "                'times': times,\n",
    "                \"category_link\": json.loads(runner.tier4_content_object['Body'])['category_link']\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f'fail:{e}')\n",
    "        return {\n",
    "            'statusCode': 500,\n",
    "            'body': json.dumps({'error': str(e)})\n",
    "        }\n",
    "\n",
    "#\n",
    "if __name__ == '__main__':\n",
    "    handler({'statusCode': 408,'times': 1, 'category_link': 'https://www.momoshop.com.tw/goods/GoodsDetail.jsp?i_code=10795343&cid=recitri&oid=BfL&mdiv=category_momoshop-cap_p2-&ctype=B&recomd_id=rgc-hqlk_normal_1692180696_195593'}, \"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80cbac6d-f1e4-4ec5-a767-21e9e0a415d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to crawl:2023-08-25 02:39:00.331086\n",
      "Starting start_requests\n",
      "tier4_content_link: https://www.momoshop.com.tw/goods/GoodsDetail.jsp?i_code=10795343&cid=recitri&oid=BfL&mdiv=category_momoshop-cap_p2-&ctype=B&recomd_id=rgc-hqlk_normal_1692180696_195593\n",
      "Starting to parse\n",
      "['個人清潔', '洗髮精/潤護髮', '精選品牌', 'FineToday日系髮品']\n",
      "08/23~08/31 結帳9折↘ 滿1件享9折(說明)08/23~08/31 滿888折100↘滿888再折100(說明)\n",
      "page_index: 2\n",
      "page_index:3\n",
      "page_index:4\n",
      "{'item_brand': 'TSUBAKI 思波綺', 'item_name': 'TSUBAKI 思波綺 升級版 瞬亮洗髮/潤髮 490ml(任選1入)', 'market_price': 290, 'promotional_price': 274, 'discounted_price': 246, 'activity': '08/23~08/31\\xa0結帳9折↘\\xa0滿1件享9折(說明)08/23~08/31\\xa0滿888折100↘滿888再折100(說明)', 'data_date': '20230825', 'item_url': 'https://www.momoshop.com.tw/goods/GoodsDetail.jsp?i_code=10795343&cid=recitri&oid=BfL&mdiv=category_momoshop-cap_p2-&ctype=B&recomd_id=rgc-hqlk_normal_1692180696_195593', 'item_spec': {'品牌名稱': 'TSUBAKI思波綺', '香味': '果香', '品牌定位': '沙龍', '包裝組合': '單入組', '功效': '柔亮滑順', '容量': '401~600ml', '適用於': '所有髮質', '產地': '日本'}, 'related_category_list': ['個人清潔|沙龍髮品|洗髮精', '個人清潔|洗髮精/潤護髮|洗髮精', '個人清潔|洗髮精/潤護髮|精選品牌|FineToday日系髮品'], 'goods_commend_indicator_average_value': 4.9, 'goods_commend_goods_commend_info': ['有評論(37)', '有圖/影片(0)', '最佳評論', '5星(70)', '4星(7)', '3星(0)', '2星(0)', '1星(0)'], 'goods_commend_indicator_quality': 4.9, 'goods_commend_indicator_accurate': 4.9, 'goods_commend_indicator_shipping': 4.9, 'goods_commend_review_card_list': [{'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/08/22', 'review_card_comment': '商品品質很好，到貨速度很快\\n常用品'}, {'review_card_score': '4', 'review_card_spec': '規格 : 瞬亮潤澤-洗髮精', 'review_card_date': '2023/08/05', 'review_card_comment': '這款洗髮乳在金門民宿用過, 覺得非常好用, 香及柔順, 記下牌子回來網購, 雖然還沒開封使用, 但應該沒錯, 當時有問民宿闆娘說有調漲, 果然沒錯.'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-潤髮乳', 'review_card_date': '2023/08/02', 'review_card_comment': '潤髮乳的味道好聞，護髮效果好'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮潤澤-洗髮精', 'review_card_date': '2023/07/29', 'review_card_comment': '多次購買 希望多多特價'}, {'review_card_score': '4', 'review_card_spec': '規格 : 瞬亮潤澤-洗髮精', 'review_card_date': '2023/07/28', 'review_card_comment': 'delivery is fast and accurate, product meets expectations, good to go for next round satisfaction is'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/07/26', 'review_card_comment': '洗起來很柔順，味道也很好聞'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/07/23', 'review_card_comment': '送貨速度快，東西好用'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-潤髮乳', 'review_card_date': '2023/07/16', 'review_card_comment': '味道很香效果也不錯哦'}, {'review_card_score': '4', 'review_card_spec': '規格 : 瞬亮潤澤-潤髮乳', 'review_card_date': '2023/07/02', 'review_card_comment': '滑順度讚'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/06/30', 'review_card_comment': '洗髮精味道很聞，洗完後髮質摸起來也很不錯！'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/06/28', 'review_card_comment': '商品包裝很漂亮，味道很好聞。'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/06/21', 'review_card_comment': '香味和紅色Tsubaki很像，洗完頭髮有點蓬鬆，滑順度的話，紅色Tsubaki較佳'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮潤澤-洗髮精', 'review_card_date': '2023/06/19', 'review_card_comment': '洗髮精很好用，一直持續有回購。'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮潤澤-潤髮乳', 'review_card_date': '2023/06/19', 'review_card_comment': '潤髮乳很好用，一直持續回購。'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-潤髮乳', 'review_card_date': '2023/06/12', 'review_card_comment': '用起來很滑順，頭髮不打結'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/06/03', 'review_card_comment': '出貨速度超快，品質優良'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮潤澤-洗髮精', 'review_card_date': '2023/06/02', 'review_card_comment': '趁有優惠促銷來屯貨,還有送贈品,真是划算~'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/06/02', 'review_card_comment': '趁有優惠促銷來屯貨,還有送贈品,真是划算~'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/05/28', 'review_card_comment': '這牌子的護髮非常讚，因此來試試看洗髮精'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/05/19', 'review_card_comment': '味道好聞，包裝好看透明'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-潤髮乳', 'review_card_date': '2023/05/17', 'review_card_comment': '送貨速度快 商品正確 下次會再購買'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮潤澤-洗髮精', 'review_card_date': '2023/05/17', 'review_card_comment': '使用後，頭髮亮澤好梳理'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮潤澤-洗髮精', 'review_card_date': '2023/05/15', 'review_card_comment': '氣味好聞，持續回購的產品'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/04/15', 'review_card_comment': '思波綺瞬亮洗髮精，味道很喜歡，洗後柔順有光澤，再次回購。'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/04/15', 'review_card_comment': '包裝完整，商品符合期待。'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/02/20', 'review_card_comment': '採用日本獨特的產品配方和山茶花精油，透過革新滲透技術，實現「無需等待的0秒沙龍級護髮」。'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/02/19', 'review_card_comment': '價格優惠,品質佳,出貨速度快,會再回購'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/02/15', 'review_card_comment': '味道可以，還沒有使用，如果好用我會持續購買！'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮潤澤-潤髮乳', 'review_card_date': '2023/02/15', 'review_card_comment': '味道可以，還沒有使用，如果好用我會持續購買！'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-潤髮乳', 'review_card_date': '2023/02/15', 'review_card_comment': '味道可以，還沒有使用，如果好用我會持續購買！'}, {'review_card_score': '4.5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/02/09', 'review_card_comment': '送貨速度非常快，東西味道很香！可以！'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮潤澤-潤髮乳', 'review_card_date': '2023/02/07', 'review_card_comment': '洗歡這香氣和柔順感！'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮潤澤-洗髮精', 'review_card_date': '2023/02/05', 'review_card_comment': '商品迅速送達且正確無損。'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮潤澤-洗髮精', 'review_card_date': '2023/02/03', 'review_card_comment': '洗髮精品質非常好，洗了之後頭髮非常柔順，感謝MOMO！'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮潤澤-潤髮乳', 'review_card_date': '2023/02/03', 'review_card_comment': '洗髮精品質非常好，洗了之後頭髮非常柔順，感謝MOMO！'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮修護-洗髮精', 'review_card_date': '2023/01/24', 'review_card_comment': '出貨超快'}, {'review_card_score': '5', 'review_card_spec': '規格 : 瞬亮潤澤-洗髮精', 'review_card_date': '2023/01/14', 'review_card_comment': '商品正確，送貨迅速，下次有需要會再購買！'}]}\n",
      "End date and time:2023-08-25 02:39:16.803733\n",
      "success\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'statusCode': 200, 'body': 'Completed!', 'times': 2}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler({'statusCode': 408,'times': 1, 'category_link': 'https://www.momoshop.com.tw/goods/GoodsDetail.jsp?i_code=10795343&cid=recitri&oid=BfL&mdiv=category_momoshop-cap_p2-&ctype=B&recomd_id=rgc-hqlk_normal_1692180696_195593'},\n",
    "         \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dc4919-f12c-445d-8bb8-8020e4c18d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
